{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximal Static Expansion for efficient parallelization on GPU\n",
    "\n",
    "## Background\n",
    "\n",
    "### Polly\n",
    "My GSoC project is part of Polly. Polly is a loop and data-locality optimizer for LLVM. The optimisations are made using a mathematical model called polyhedral model. It models the memory access of the program. After modeling, transformations (tilling, loop fusion, loop unrolling ...) can be applied on the model to improve data-locality and/or parallelization. The aim of my project was to implement a transformation called Maximal Static Expansion (MSE).\n",
    "\n",
    "TODO : explain SCop, Stamtenet, Memory Acecss, SAI\n",
    "\n",
    "### ISL\n",
    "ISL is the **I**nteger **S**et **L**ibrary used in Polly to handle all the mathematical computation during modelling and transformation. A basic understanding of what is ISL and how to use it is necessary to understand the implementation part of this report.\n",
    "\n",
    "#### Data structures\n",
    "ISL has different types of data structures.\n",
    "* **Set** :\n",
    "A set in ISL is represented as follow :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\{ S[i_0, ..., i_n] : c_0, ..., c_n\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $i_k$ is an input variable and $c_k$ is a constraint.\n",
    "\n",
    "For example, the set of all instances of the statement S of the following code source is $\\{ S[i, j] : i=j, 0 \\le i \\le N, 0 \\le j \\le N\\}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (int i = 0; i < N; i++)\n",
    "  for (int j = 0; j < N; j++)\n",
    "    if (i == j)\n",
    "S:    A[i][j+1] = i*j;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Union Set** :\n",
    "An union set is just an union of set.\n",
    "\n",
    "* **Map** : A map in ISL represents a relation. It is represented as follow :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\{ S[i_0, ..., i_n] \\rightarrow T[o_0, ..., o_n] : c_0, ..., c_n\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $i_k$ is an input variable, $o_k$ is an output variable and $c_k$ is a constraint.\n",
    "\n",
    "For example, to model the memory access inside the statement S of the preeceding example, the corresponding map is :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\{ S[i, j] \\rightarrow A[i, j+1] : i=j, 0 \\le i \\le N, 0 \\le j \\le N \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This map means that in the statement S, there is a memory access to the array A at the indices [i, j+1].\n",
    "\n",
    "**BE CAREFUL** : there is implicit constraints in this map. An unsimplified version of this map is :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\{ S[i_0, i_1] \\rightarrow A[o_0, o_1] : i_0=i_1, i_0=o_0, i_1=o_1-1\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input part of the map is called the domain whereas the output part is called the range. For example, the domain and the range of the previous map are :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ domain(\\{ S[i, j] \\rightarrow A[i, j+1] : i=j\\}) = \\{ S[i, j] : i=j\\} $$\n",
    "$$ range(\\{ S[i, j] \\rightarrow A[i, j+1] : i=j\\}) = \\{ A[i, j+1] : i=j\\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Union Map** : An union map is just an union of map.\n",
    "\n",
    "* **Nested Map** : There is a specific type of map called nested map. The structure is the following :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\{ [ S[i_0, ..., i_n] \\rightarrow T[j_0, ..., j_n] ] \\rightarrow [ U[k_0, ..., k_n] \\rightarrow V[l_0, ..., l_n] ] : c_0, ... , c_n\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this kind of data structure, we can represent data dependencies. Let take an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (int i = 0; i < N; i++) {\n",
    "   for (int j = 0; j < N; j++) {\n",
    "S:   B[i][j] = i*j;;\n",
    "   }\n",
    "T: A[i] = B[0][i];\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a RAW dependency for the array B because we read index i of B in statement T after that the statement S has written to index j of B. The dependences map looks like :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\{ [ T[i] \\rightarrow B[0, i] ] \\rightarrow [ S[i, j] \\rightarrow B[i, j] ] : 0 \\le i \\le N, 0 \\le j \\le N \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximal static expansion\n",
    "Data-dependences in a program can lead to a very bad automatic parallelization. Modern compilers use techniques to reduce the number of such dependences. One of them is Maximal Static Expansion. The MSE is a transformation which expand the memory access to and from Array or Scalar. The goal is to disambiguate memory accesses by assigning different memory locations to non-conflicting writes. This method is described in a paper written by Denis Barthou, Albert Cohen and Jean-Francois Collard.[^f1] \n",
    "Let take a example (from the article) to understand the principle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int tmp;\n",
    "for (int i = 0; i < N; i++) {\n",
    "    tmp = i;\n",
    "    for (int j = 0; j < N; j++) {\n",
    "        tmp = tmp + i + j;\n",
    "    }\n",
    "    A[i] = tmp;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data-dependences induced by tmp make the two loops unparallelizable : the iteration j of the inner-loop needs value from the previous iteration and it is impossible to parrallelize the i-loop because tmp is used in all iterations.\n",
    "\n",
    "If we expand the accesses to tmp according to the outermost loop, we can then parallelize the i-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int tmp_exp[N];\n",
    "for (int i = 0; i < N; i++) {\n",
    "    tmp_exp[i] = i;\n",
    "    for (int j = 0; j < N; j++) {\n",
    "        tmp_exp[i] = tmp_exp[i] + i + j;\n",
    "    }\n",
    "    A[i] = tmp_exp[i];\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accesses to tmp are now made to/from a different location for each iteration of the i-loop. It is then possible to execute the different iteration on different computation units (GPU, CPU ...).\n",
    "\n",
    "### Static single assignement\n",
    "Due to lack of time, I was not able to implement **maximal** static expansion but only fully-indexed expansion. The principle of fully-index expansion is that each write goes to a different memory location. \n",
    "Let see the idea on an example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int tmp;\n",
    "for (int i = 0; i < N; i++) {\n",
    "    tmp = i;\n",
    "    for (int j = 0; j < N; j++) {\n",
    "        B[j] = tmp + 3;\n",
    "    }\n",
    "    A[i] = B[i];\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity, only the arrays will be expanded in this example. The fully expanded version is :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int tmp;\n",
    "for (int i = 0; i < N; i++) {\n",
    "    tmp = i;\n",
    "    for (int j = 0; j < N; j++) {\n",
    "        B_exp[i][j] = tmp + 3;\n",
    "    }\n",
    "    A_exp[i] = B_exp[i][i];\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The details of fully-indexed expansion will be discussed in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## My work\n",
    "My project is part of Polly. I am a french student but during the GSoC I was a student at the university of Passau, Germany. The LooPo team welcome me and more especially Andreas SimbÃ¼rger, one of my GSoC mentor and my master thesis supervisor. My other GSoC mentor is Michael Kruse, one of the main contributor to Polly, actually working in France.\n",
    "I'd like to thank all the people that help and guide me and more especially Andreas and Michael. \n",
    "\n",
    "### JSON bug fix\n",
    "As first step in open source software development and to get familiar with Polly/LLVM development process, I fixed a open bug in Polly. Polly can import data from a JSON file (in case of Polly called jscop file). It can import new array, new memory access, new schedule or new context. In the previous implementation of JSONImporter, Polly did not check if the data in the jscop file were plausible and consistent before import. This can lead to failure in the remaining part of the Polly pipeline. My work was to implement plausibility and consistency checks. Details, diff and discussions can be found here : https://reviews.llvm.org/D32739. This patch has been merged into the actual version of Polly.\n",
    "\n",
    "### Allocate array on heap\n",
    "During transformation, Polly can create new arrays because it helps optimizing the program. Before GSoC, it was only possible to allocate array on the stack. It is sufficient for small arrays, but while doing expansion, we possibly handle very large arrays. For example, if we want to expand fully this simple code :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (int i = 0; i < N; i++)\n",
    "  for (int j = 0; j < N; j++)\n",
    "    for (int k = 0; k < N; k++)\n",
    "      for (int l = 0; l < N; l++)\n",
    "        A[l] = 3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expansion would lead to the following code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (int i = 0; i < N; i++)\n",
    "  for (int j = 0; j < N; j++)\n",
    "    for (int k = 0; k < N; k++)\n",
    "      for (int l = 0; l < N; l++)\n",
    "        A_exp[i][j][k][l] = 3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the value of N, A_exp can have a huge number of elements. If N = 100, we have $100*100*100*100 = 100000000 = 10^8$ elements ! Thus, the possibility to allocate array on heap was needed. \n",
    "\n",
    "The array allocation is implemented in the IslNodeBuilder. Here is the part of the code that do the allocation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "void IslNodeBuilder::allocateNewArrays(BBPair StartExitBlocks) {\n",
    "  for (auto &SAI : S.arrays()) {\n",
    "    if (SAI->getBasePtr())\n",
    "      continue;\n",
    "\n",
    "    assert(SAI->getNumberOfDimensions() > 0 && SAI->getDimensionSize(0) &&\n",
    "           \"The size of the outermost dimension is used to declare newly \"\n",
    "           \"created arrays that require memory allocation.\");\n",
    "\n",
    "    Type *NewArrayType = nullptr;\n",
    "\n",
    "    // Get the size of the array = size(dim_1)*...*size(dim_n)\n",
    "    uint64_t ArraySizeInt = 1;\n",
    "    for (int i = SAI->getNumberOfDimensions() - 1; i >= 0; i--) {\n",
    "      auto *DimSize = SAI->getDimensionSize(i);\n",
    "      unsigned UnsignedDimSize = static_cast<const SCEVConstant *>(DimSize)\n",
    "                                     ->getAPInt()\n",
    "                                     .getLimitedValue();\n",
    "\n",
    "      if (!NewArrayType)\n",
    "        NewArrayType = SAI->getElementType();\n",
    "\n",
    "      NewArrayType = ArrayType::get(NewArrayType, UnsignedDimSize);\n",
    "      ArraySizeInt *= UnsignedDimSize;\n",
    "    }\n",
    "\n",
    "    if (SAI->isOnHeap()) {\n",
    "      LLVMContext &Ctx = NewArrayType->getContext();\n",
    "\n",
    "      // Get the IntPtrTy from the Datalayout\n",
    "      auto IntPtrTy = DL.getIntPtrType(Ctx);\n",
    "\n",
    "      // Get the size of the element type in bits\n",
    "      unsigned Size = SAI->getElemSizeInBytes();\n",
    "\n",
    "      // Insert the malloc call at polly.start\n",
    "      auto InstIt = std::get<0>(StartExitBlocks)->getTerminator();\n",
    "      auto *CreatedArray = CallInst::CreateMalloc(\n",
    "          &*InstIt, IntPtrTy, SAI->getElementType(),\n",
    "          ConstantInt::get(Type::getInt64Ty(Ctx), Size),\n",
    "          ConstantInt::get(Type::getInt64Ty(Ctx), ArraySizeInt), nullptr,\n",
    "          SAI->getName());\n",
    "\n",
    "      SAI->setBasePtr(CreatedArray);\n",
    "\n",
    "      // Insert the free call at polly.exiting\n",
    "      CallInst::CreateFree(CreatedArray,\n",
    "                           std::get<1>(StartExitBlocks)->getTerminator());\n",
    "\n",
    "    } else {\n",
    "      auto InstIt = Builder.GetInsertBlock()\n",
    "                        ->getParent()\n",
    "                        ->getEntryBlock()\n",
    "                        .getTerminator();\n",
    "\n",
    "      auto *CreatedArray = new AllocaInst(NewArrayType, DL.getAllocaAddrSpace(),\n",
    "                                          SAI->getName(), &*InstIt);\n",
    "      CreatedArray->setAlignment(PollyTargetFirstLevelCacheLineSize);\n",
    "      SAI->setBasePtr(CreatedArray);\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My work in this method is the size computation and the heap allocation part. The remaining code was already in place.\n",
    "\n",
    "Let explain step by step the principle of the heap allocation.\n",
    "\n",
    "First of all, to allocate array, we need to have the size of the memory chunk we want to allocate. To do that, we simply iterate over the dimension of the ScopArrayInfo and multiply the size of each dimensions. This is done by this code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    // Get the size of the array = size(dim_1)*...*size(dim_n)\n",
    "    uint64_t ArraySizeInt = 1;\n",
    "    for (int i = SAI->getNumberOfDimensions() - 1; i >= 0; i--) {\n",
    "      auto *DimSize = SAI->getDimensionSize(i);\n",
    "      unsigned UnsignedDimSize = static_cast<const SCEVConstant *>(DimSize)\n",
    "                                     ->getAPInt()\n",
    "                                     .getLimitedValue();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually do the expansion, we need to add a malloc call at the beginning of the polly section, called polly.start. After each malloc, a free must be present. The free call is added at polly.end. These two BasicBlock (polly.start and polly.end) are passed to allocateNewArray as a BBPair. We choose polly.start and polly.end as insertion points after a dense discussion with the polly community because this certify that there is no use-after-free (for instance in case of Scop in a loop) and that all memory cells allocated with a malloc are free'd when we don't need them anymore.\n",
    "\n",
    "To get polly.start and polly.end, we modify executeScopConditionnaly such that it return both start block and end block of the scop. In the previous version of Polly, executeScopConditionnaly only return polly.start. People who wanted polly.end assume that there is no BasicBlock between polly.start and polly.end, so they just take the successor of polly.start. \n",
    "\n",
    "The malloc call insertion is made by this code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    auto *CreatedArray = CallInst::CreateMalloc(\n",
    "              &*InstIt, IntPtrTy, SAI->getElementType(),\n",
    "              ConstantInt::get(Type::getInt64Ty(Ctx), Size),\n",
    "              ConstantInt::get(Type::getInt64Ty(Ctx), ArraySizeInt), nullptr,\n",
    "              SAI->getName());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The free call insertion is made by this code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    CallInst::CreateFree(CreatedArray, std::get<1>(StartExitBlocks)->getTerminator());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details, diff and discussions can be found here : https://reviews.llvm.org/D33688. This patch has been merged into the actual version of Polly.\n",
    "\n",
    "### Array Fully indexed exp\n",
    "#### Principle\n",
    "As a first step in term of expansion, we choose to expand only arrays because we thought that it was an easy step to build expansion infrastructure. We also choose to no implement the **maximal** expansion in this step, to focus our efforts on the architecture of expansion : we implement a Fully-index expansion. The principle is that, for each array in the Scop, we expand the write to the array according to the loop nest and then we map the reads to the right iteration of the newly create ScopArrayInfo. Let see this on an example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int tmp;\n",
    "for (int i = 0; i < N; i++) {\n",
    "    tmp = i;\n",
    "    for (int j = 0; j < N; j++) {\n",
    "S:      B[j] = tmp + 3;\n",
    "    }\n",
    "T:  A[i] = B[i];\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The write to B occurs inside the i and j loops. Therefore, the expanded version of B must be a two-dimensional array indexed by i and j. The write to A occurs inside the i loop only, therefore it would no need expansion. But for the sake of simplicity, we still create an expanded version of A. After write expansion, the code would look like that :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int tmp;\n",
    "for (int i = 0; i < N; i++) {\n",
    "    tmp = i;\n",
    "    for (int j = 0; j < N; j++) {\n",
    "S:      B_exp[i][j] = tmp + 3;\n",
    "    }\n",
    "T:  A_exp[i] = B[i];\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no read from A, so the expansion of A is done. There is a read from B in the statement T. At this step, we need the RAW dependences. In our case, statement T depends on statement S because the memory location reads by statement T is written by statetement S during j-loop iterations. The dependency looks like :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\{ T[i] \\rightarrow S[i][i] : 0\\le i \\le N \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know that the statement T must read its value from the statement S at index [i,i], we only have to know the name of the expanded version of B and modify the read. After read expansion, the source code looks like that :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int tmp;\n",
    "for (int i = 0; i < N; i++) {\n",
    "    tmp = i;\n",
    "    for (int j = 0; j < N; j++) {\n",
    "S:      B_exp[i][j] = tmp + 3;\n",
    "    }\n",
    "T:  A_exp[i] = B_exp[i][i];\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More details can be found in these two articles[^f2][^f3].\n",
    "\n",
    "#### Implementation\n",
    "Let see now how this principle has been implemented in Polly.\n",
    "\n",
    "Static expansion has been implemented as a ScopPass, which is a Pass triggered on every Scop detected by Polly. Guarded by an option, it is possible to ask Polly to do the expansion by adding **-polly-enable-mse** to clang or **-polly-mse** to opt command line. \n",
    "\n",
    "Here is the 'main' of static expansion. This code is straightforward and explains by itself the idea of expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  // Get the RAW Dependences.\n",
    "  auto &DI = getAnalysis<DependenceInfo>();\n",
    "  auto &D = DI.getDependences(Dependences::AL_Reference);\n",
    "  auto Dependences = isl::give(D.getDependences(Dependences::TYPE_RAW));\n",
    "\n",
    "  for (auto SAI : S.arrays()) {\n",
    "    SmallPtrSet<MemoryAccess *, 4> AllWrites;\n",
    "    SmallPtrSet<MemoryAccess *, 4> AllReads;\n",
    "    if (!isExpandable(SAI, AllWrites, AllReads, S, Dependences))\n",
    "      continue;\n",
    "\n",
    "    auto TheWrite = *(AllWrites.begin());\n",
    "    ScopArrayInfo *ExpandedArray = expandWrite(S, TheWrite);\n",
    "\n",
    "    for (MemoryAccess *MA : AllReads)\n",
    "      expandRead(S, MA, Dependences, ExpandedArray);\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three first line is just the way to get dependences from Polly infrastructure. We request the DependenceInfo analysis for RAW dependences, using the Reference level statement. In a first iteration, we were using Statement Level statement. But this causes bugs. Full discussion and bug fixing can be found here :  https://reviews.llvm.org/D36791.\n",
    "\n",
    "Then, we iterate over ScopArrayInfo in the Scop we are processing. We check if the ScopArrayInfo is expandable. If yes, we expand the write following the principle describe below and after we expand the reads.\n",
    "\n",
    "The method $isExpandable$ say wheter or not the current ScopArrayInfo is expandable or not. The idea of this method is to iterate over the ScopStatement of the ScopArrayInfo passed in parameter and find cases where we can **not** do the expansion. At this step of implementation, we bail out in these cases :\n",
    "* When the ScopArrayInfo involves Scalar, because we are not, at this step, able to expand scalar.\n",
    "* When inside a ScopStatement, a read come after a write.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (int i = 0; i < N; i++) {\n",
    "    for (int j = 0; j < N; j++) {\n",
    "        B[i] = ... ;\n",
    "        ... = B[i];\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polly will model the two instructions as one ScopStatement and detect two memory access inside this statement :\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read : \n",
    "$$\\{ S[i, j] \\rightarrow B[i] : 0 \\le i \\le N, 0 \\le j \\le N \\}$$\n",
    "Write :\n",
    "$$\\{ S[i, j] \\rightarrow B[i] : 0 \\le i \\le N, 0 \\le j \\le N \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then Polly will give these two memory access to ISL. But ISL has no information on the order in which the memory access appears so it decide that the read come first, which is not the case in our example. So we need to bail out in such cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When the ScopArrayInfo has MayWrite access.\n",
    "* When the ScopArrayInfo has more than one write because the expansion would lead to an union map as access relation, which is not possible inside Polly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (int i = 0; i < N; i++) {\n",
    "    B[i] = ... ;\n",
    "    for (int j = 0; j < N; j++) {\n",
    "        B[j] = ... ;\n",
    "    }\n",
    "    ... = B[i];\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only-write expanded version of this example would look like this :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (int i = 0; i < N; i++) {\n",
    "    B_exp[i] = ... ;\n",
    "    for (int j = o; j < M; j++) {\n",
    "        B_exp2[i][j] = ... ;\n",
    "    }\n",
    "    ... = B[i+2];\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read of B can read either from B_exp or from B_exp2. Its memory access relation would look like, assuming that $N>M$ :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\{ T[i] \\rightarrow B\\_exp[i] : i \\ge M, 0 \\le i \\le N, 0 \\le j \\le M \\ ; T[i] \\rightarrow B\\_exp2[i][i] : i < M, 0 \\le i \\le N, 0 \\le j \\le M \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When there are too many dependences in the dependences map.\n",
    "* When the expansion would lead to a read from the original array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (int i = 0; i < N; i++) {\n",
    "    ... = B[i];\n",
    "    for (int j = 0; j < N; j++) {\n",
    "        B[j] = ... ;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expanded version of this example would look like :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (int i = 0; i < N; i++) {\n",
    "    ... = B_exp[i][i];\n",
    "    for (int j = 0; j < N; j++) {\n",
    "        B_exp[i][j] = ... ;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is that nobody is writing $B\\_exp[i][i]$ before it is reading. So we need a copy in mechanism to manually copy data to $B\\_exp$ from the original array. This mechanism is not yet implemented. \n",
    "* When there are no writes.\n",
    "\n",
    "Here is the full $isExpandable$ method :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bool MaximalStaticExpander::isExpandable(\n",
    "    const ScopArrayInfo *SAI, SmallPtrSetImpl<MemoryAccess *> &Writes,\n",
    "    SmallPtrSetImpl<MemoryAccess *> &Reads, Scop &S,\n",
    "    const isl::union_map &Dependences) {\n",
    "\n",
    "  int NumberWrites = 0;\n",
    "  for (ScopStmt &Stmt : S) {\n",
    "    auto StmtReads = isl::union_map::empty(S.getParamSpace());\n",
    "    auto StmtWrites = isl::union_map::empty(S.getParamSpace());\n",
    "\n",
    "    for (MemoryAccess *MA : Stmt) {\n",
    "\n",
    "      // Check if the current MemoryAccess involved the current SAI.\n",
    "      if (SAI != MA->getLatestScopArrayInfo())\n",
    "        continue;\n",
    "\n",
    "      // For now, we are not able to expand Scalar.\n",
    "      if (MA->isLatestScalarKind()) {\n",
    "        emitRemark(SAI->getName() + \" is a Scalar access.\",\n",
    "                   MA->getAccessInstruction());\n",
    "        return false;\n",
    "      }\n",
    "\n",
    "      // For now, we are not able to expand array where read come after write\n",
    "      // (to the same location) in a same statement.\n",
    "      auto AccRel = isl::union_map(MA->getAccessRelation());\n",
    "      if (MA->isRead()) {\n",
    "        // Reject load after store to same location.\n",
    "        if (!StmtWrites.is_disjoint(AccRel)) {\n",
    "          emitRemark(SAI->getName() + \" has read after write to the same \"\n",
    "                                      \"element in same statement. The \"\n",
    "                                      \"dependences found during analysis may \"\n",
    "                                      \"be wrong because Polly is not able to \"\n",
    "                                      \"handle such case for now.\",\n",
    "                     MA->getAccessInstruction());\n",
    "          return false;\n",
    "        }\n",
    "\n",
    "        StmtReads = give(isl_union_map_union(StmtReads.take(), AccRel.take()));\n",
    "      } else {\n",
    "        StmtWrites =\n",
    "            give(isl_union_map_union(StmtWrites.take(), AccRel.take()));\n",
    "      }\n",
    "\n",
    "      // For now, we are not able to expand MayWrite.\n",
    "      if (MA->isMayWrite()) {\n",
    "        emitRemark(SAI->getName() + \" has a maywrite access.\",\n",
    "                   MA->getAccessInstruction());\n",
    "        return false;\n",
    "      }\n",
    "\n",
    "      // For now, we are not able to expand SAI with more than one write.\n",
    "      if (MA->isMustWrite()) {\n",
    "        Writes.insert(MA);\n",
    "        NumberWrites++;\n",
    "        if (NumberWrites > 1) {\n",
    "          emitRemark(SAI->getName() + \" has more than 1 write access.\",\n",
    "                     MA->getAccessInstruction());\n",
    "          return false;\n",
    "        }\n",
    "      }\n",
    "\n",
    "      // Check if it is possible to expand this read.\n",
    "      if (MA->isRead()) {\n",
    "\n",
    "        // Get the domain of the current ScopStmt.\n",
    "        auto StmtDomain = Stmt.getDomain();\n",
    "\n",
    "        // Get the domain of the future Read access.\n",
    "\n",
    "        auto ReadDomainSet = MA->getAccessRelation().domain();\n",
    "        auto ReadDomain = isl::union_set(ReadDomainSet);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        // Get the dependences relevant for this MA\n",
    "        auto MapDependences = filterDependences(S, Dependences, MA);\n",
    "        auto DepsDomain = MapDependences.domain();\n",
    "        unsigned NumberElementMap = isl_union_map_n_map(MapDependences.get());\n",
    "\n",
    "        // If there are multiple maps in the Deps, we cannot handle this case\n",
    "        // for now.\n",
    "        if (NumberElementMap != 1) {\n",
    "          emitRemark(SAI->getName() +\n",
    "                         \" has too many dependences to be handle for now.\",\n",
    "                     MA->getAccessInstruction());\n",
    "          return false;\n",
    "        }\n",
    "\n",
    "        auto DepsDomainSet = isl::set(DepsDomain);\n",
    "\n",
    "        // For now, read from the original array is not possible.\n",
    "        if (!StmtDomain.is_subset(DepsDomainSet)) {\n",
    "          emitRemark(\"The expansion of \" + SAI->getName() +\n",
    "                         \" would lead to a read from the original array.\",\n",
    "                     MA->getAccessInstruction());\n",
    "          return false;\n",
    "        }\n",
    "\n",
    "        Reads.insert(MA);\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // No need to expand SAI with no write.\n",
    "  if (NumberWrites == 0) {\n",
    "    emitRemark(SAI->getName() + \" has 0 write access.\",\n",
    "               S.getEnteringBlock()->getFirstNonPHI());\n",
    "    return false;\n",
    "  }\n",
    "\n",
    "  return true;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method $expandWrite$ is pretty simple. As its name suggests, the aim of this method is to expand write access. Here is a textual description of the algorithm.\n",
    "\n",
    "Get the current access relation map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  // Get domain from the current AM.\n",
    "  auto Domain = CurrentAccessMap.domain();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add output dimensions according to the loop nest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  unsigned in_dimensions = CurrentAccessMap.dim(isl::dim::in);\n",
    "\n",
    "  // Add dimensions to the new AM according to the current in_dim.\n",
    "  NewAccessMap = NewAccessMap.add_dims(isl::dim::out, in_dimensions);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get or Create the expanded ScopArrayInfo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " // Create the string representing the name of the new SAI.\n",
    "  // One new SAI for each statement so that each write go to a different memory\n",
    "  // cell.\n",
    "  auto CurrentStmtDomain = MA->getStatement()->getDomain();\n",
    "  auto CurrentStmtName = CurrentStmtDomain.get_tuple_name();\n",
    "  auto CurrentOutId = CurrentAccessMap.get_tuple_id(isl::dim::out);\n",
    "  std::string CurrentOutIdString =\n",
    "      MA->getScopArrayInfo()->getName() + \"_\" + CurrentStmtName + \"_expanded\";\n",
    "\n",
    "  // Create the size vector.\n",
    "  std::vector<unsigned> Sizes;\n",
    "  for (unsigned i = 0; i < in_dimensions; i++) {\n",
    "    assert(isDimBoundedByConstant(CurrentStmtDomain, i) &&\n",
    "           \"Domain boundary are not constant.\");\n",
    "    auto UpperBound = getConstant(CurrentStmtDomain.dim_max(i), true, false);\n",
    "    assert(!UpperBound.is_null() && UpperBound.is_pos() &&\n",
    "           !UpperBound.is_nan() &&\n",
    "           \"The upper bound is not a positive integer.\");\n",
    "    assert(UpperBound.le(isl::val(CurrentAccessMap.get_ctx(),\n",
    "                                  std::numeric_limits<int>::max() - 1)) &&\n",
    "           \"The upper bound overflow a int.\");\n",
    "    Sizes.push_back(UpperBound.get_num_si() + 1);\n",
    "  }\n",
    "\n",
    "  // Get the ElementType of the current SAI.\n",
    "  auto ElementType = MA->getLatestScopArrayInfo()->getElementType();\n",
    "\n",
    "  // Create (or get if already existing) the new expanded SAI.\n",
    "  auto ExpandedSAI =\n",
    "      S.createScopArrayInfo(ElementType, CurrentOutIdString, Sizes);\n",
    "  ExpandedSAI->setIsOnHeap(true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the out tuple id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  // Set the out id of the new AM to the new SAI id.\n",
    "  NewAccessMap = NewAccessMap.set_tuple_id(isl::dim::out, NewOutId);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add constraints to link input and ouput variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  // Add constraints to linked output with input id.\n",
    "  auto SpaceMap = NewAccessMap.get_space();\n",
    "  auto ConstraintBasicMap =\n",
    "      isl::basic_map::equal(SpaceMap, SpaceMap.dim(isl::dim::in));\n",
    "  NewAccessMap = isl::map(ConstraintBasicMap);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the new access relation to the memory access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  // Set the new access relation map.\n",
    "  MA->setNewAccessRelation(NewAccessMap);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We return the expanded ScopArrayInfo for the sake of simplicity because we will need it in the $expandRead$ method. Here is the full code of $expandWrite$ method :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ScopArrayInfo *MaximalStaticExpander::expandWrite(Scop &S, MemoryAccess *MA) {\n",
    "\n",
    "  // Get the current AM.\n",
    "  auto CurrentAccessMap = MA->getAccessRelation();\n",
    "\n",
    "  unsigned in_dimensions = CurrentAccessMap.dim(isl::dim::in);\n",
    "\n",
    "  // Get domain from the current AM.\n",
    "  auto Domain = CurrentAccessMap.domain();\n",
    "\n",
    "  // Create a new AM from the domain.\n",
    "  auto NewAccessMap = isl::map::from_domain(Domain);\n",
    "\n",
    "  // Add dimensions to the new AM according to the current in_dim.\n",
    "  NewAccessMap = NewAccessMap.add_dims(isl::dim::out, in_dimensions);\n",
    "\n",
    "  // Create the string representing the name of the new SAI.\n",
    "  // One new SAI for each statement so that each write go to a different memory\n",
    "  // cell.\n",
    "  auto CurrentStmtDomain = MA->getStatement()->getDomain();\n",
    "  auto CurrentStmtName = CurrentStmtDomain.get_tuple_name();\n",
    "  auto CurrentOutId = CurrentAccessMap.get_tuple_id(isl::dim::out);\n",
    "  std::string CurrentOutIdString =\n",
    "      MA->getScopArrayInfo()->getName() + \"_\" + CurrentStmtName + \"_expanded\";\n",
    "\n",
    "  // Set the tuple id for the out dimension.\n",
    "  NewAccessMap = NewAccessMap.set_tuple_id(isl::dim::out, CurrentOutId);\n",
    "\n",
    "  // Create the size vector.\n",
    "  std::vector<unsigned> Sizes;\n",
    "  for (unsigned i = 0; i < in_dimensions; i++) {\n",
    "    assert(isDimBoundedByConstant(CurrentStmtDomain, i) &&\n",
    "           \"Domain boundary are not constant.\");\n",
    "    auto UpperBound = getConstant(CurrentStmtDomain.dim_max(i), true, false);\n",
    "    assert(!UpperBound.is_null() && UpperBound.is_pos() &&\n",
    "           !UpperBound.is_nan() &&\n",
    "           \"The upper bound is not a positive integer.\");\n",
    "    assert(UpperBound.le(isl::val(CurrentAccessMap.get_ctx(),\n",
    "                                  std::numeric_limits<int>::max() - 1)) &&\n",
    "           \"The upper bound overflow a int.\");\n",
    "    Sizes.push_back(UpperBound.get_num_si() + 1);\n",
    "  }\n",
    "\n",
    "  // Get the ElementType of the current SAI.\n",
    "  auto ElementType = MA->getLatestScopArrayInfo()->getElementType();\n",
    "\n",
    "  // Create (or get if already existing) the new expanded SAI.\n",
    "  auto ExpandedSAI =\n",
    "      S.createScopArrayInfo(ElementType, CurrentOutIdString, Sizes);\n",
    "  ExpandedSAI->setIsOnHeap(true);\n",
    "\n",
    "  // Get the out Id of the expanded Array.\n",
    "  auto NewOutId = ExpandedSAI->getBasePtrId();\n",
    "\n",
    "  // Set the out id of the new AM to the new SAI id.\n",
    "  NewAccessMap = NewAccessMap.set_tuple_id(isl::dim::out, NewOutId);\n",
    "\n",
    "  // Add constraints to linked output with input id.\n",
    "  auto SpaceMap = NewAccessMap.get_space();\n",
    "  auto ConstraintBasicMap =\n",
    "      isl::basic_map::equal(SpaceMap, SpaceMap.dim(isl::dim::in));\n",
    "  NewAccessMap = isl::map(ConstraintBasicMap);\n",
    "\n",
    "  // Set the new access relation map.\n",
    "  MA->setNewAccessRelation(NewAccessMap);\n",
    "\n",
    "  return ExpandedSAI;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As its name suggests, the $expandRead$ method expand the read access passed in parameter. The algorithm is pretty simple too. The goal is to map the read to the last write to the array involved.\n",
    "\n",
    "First, we get the RAW dependences relevant for the read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  // Get RAW dependences for the current WA.\n",
    "  auto WriteDomainSet = MA->getAccessRelation().domain();\n",
    "  auto WriteDomain = isl::union_set(WriteDomainSet);\n",
    "\n",
    "  // Get the dependences relevant for this MA\n",
    "  auto MapDependences = filterDependences(S, Dependences, MA);\n",
    "\n",
    "  // If no dependences, no need to modify anything.\n",
    "  if (MapDependences.is_empty())\n",
    "    return;\n",
    "\n",
    "\n",
    "  assert(isl_union_map_n_map(MapDependences.get()) == 1 &&\n",
    "         \"There are more than one RAW dependencies in the union map.\");\n",
    "  auto NewAccessMap = isl::map::from_union_map(MapDependences);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $filterDependences$ method only filter the relevant dependences.\n",
    "\n",
    "Then we set the out id of the map with the id of the expanded array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  auto Id = ExpandedSAI->getBasePtrId();\n",
    "\n",
    "  // Replace the out tuple id with the one of the access array.\n",
    "  NewAccessMap = NewAccessMap.set_tuple_id(isl::dim::out, Id);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end, we set the new access relation to the memory access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  // Set the new access relation.\n",
    "  MA->setNewAccessRelation(NewAccessMap);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the full version of $expandRead$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "void MaximalStaticExpander::expandRead(Scop &S, MemoryAccess *MA,\n",
    "                                       const isl::union_map &Dependences,\n",
    "                                       ScopArrayInfo *ExpandedSAI) {\n",
    "\n",
    "  // Get the current AM.\n",
    "  auto CurrentAccessMap = MA->getAccessRelation();\n",
    "\n",
    "  // Get RAW dependences for the current WA.\n",
    "  auto WriteDomainSet = MA->getAccessRelation().domain();\n",
    "  auto WriteDomain = isl::union_set(WriteDomainSet);\n",
    "\n",
    "  // Get the dependences relevant for this MA\n",
    "  auto MapDependences = filterDependences(S, Dependences, MA);\n",
    "\n",
    "  // If no dependences, no need to modify anything.\n",
    "  if (MapDependences.is_empty())\n",
    "    return;\n",
    "\n",
    "\n",
    "  assert(isl_union_map_n_map(MapDependences.get()) == 1 &&\n",
    "         \"There are more than one RAW dependencies in the union map.\");\n",
    "  auto NewAccessMap = isl::map::from_union_map(MapDependences);\n",
    "\n",
    "  auto Id = ExpandedSAI->getBasePtrId();\n",
    "\n",
    "  // Replace the out tuple id with the one of the access array.\n",
    "  NewAccessMap = NewAccessMap.set_tuple_id(isl::dim::out, Id);\n",
    "\n",
    "  // Set the new access relation.\n",
    "  MA->setNewAccessRelation(NewAccessMap);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details, diff and discussions can be found here : https://reviews.llvm.org/D34982. This patch and the bug fixing one have been merged into the actual version of Polly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar Fully indexed exp\n",
    "\n",
    "Polly has two mains manner of representing scalars. The first one is called MemoryKind::Value. A single memory write stores value at its definition into the memory object and at each use of the value a corresponding read is added. \n",
    "\n",
    "The second one is called MemoryKind::PHI. A PHI node represent the fact that a scalar can have multiples sources. Let take an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int tmp = 0;\n",
    "for (int i = 0; i < N; i++) {\n",
    "    tmp = tmp + 2;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In LLVM, everything is transformed in SSA. This means that Polly see the following source code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int tmp = 0;\n",
    "for (int i = 0; i < N; i++) {\n",
    "    tmp_1 = PHI(tmp, tmp_2)\n",
    "    tmp_2 = tmp_1 + 2;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$tmp\\_1$ has not always the same source depending on the iteration the i-loop is in. If i=0, the source is tmp otherwise the source is tmp_2 of the previous iteration.\n",
    "\n",
    "The expansion of MemoryKind::Value is trivial because it behave well into the MemoryKind::Array expansion algorithm.\n",
    "\n",
    "The expansion of MemoryKind::PHI have asked a bit of work. A PHI can have only one read and multiple writes. So to expand PHI, we just exchange the role of read and writes in comparison to MemoryKind::Array expansion. This means that we expand the read access and maps the write accesses. To do that, we have refactor $expandRead$ and $expandWrite$ respectively as $mapAccess$ and $expandAccess$. $mapAccess$ do exactly the same things as before, but now take a set of MemoryAccess to expand. We also add a method called $expandPHI$ responsible for the expansion of PHI node. \n",
    "\n",
    "Let see how $expandPHI$ works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "void MaximalStaticExpander::expandPhi(Scop &S, const ScopArrayInfo *SAI,\n",
    "                                      const isl::union_map &Dependences) {\n",
    "  SmallPtrSet<MemoryAccess *, 4> Writes;\n",
    "  for (auto MA : S.getPHIIncomings(SAI))\n",
    "    Writes.insert(MA);\n",
    "  auto Read = S.getPHIRead(SAI);\n",
    "  auto ExpandedSAI = expandAccess(S, Read);\n",
    "\n",
    "  mapAccess(S, Writes, Dependences, ExpandedSAI, false);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is pretty simple. First of all, we query for read (S.getPHIRead) and writes (S.getPHIIncomings). Then we ask $expandAccess$ to expand the read and $mapAccess$ to map the set of writes. And that's all !\n",
    "\n",
    "The 'main' method of expansion now looks like :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bool MaximalStaticExpander::runOnScop(Scop &S) {\n",
    "\n",
    "  // Get the RAW Dependences.\n",
    "  auto &DI = getAnalysis<DependenceInfo>();\n",
    "  auto &D = DI.getDependences(Dependences::AL_Reference);\n",
    "  auto Dependences = isl::give(D.getDependences(Dependences::TYPE_RAW));\n",
    "\n",
    "  for (auto SAI : S.arrays()) {\n",
    "    SmallPtrSet<MemoryAccess *, 4> AllWrites;\n",
    "    SmallPtrSet<MemoryAccess *, 4> AllReads;\n",
    "    if (!isExpandable(SAI, AllWrites, AllReads, S, Dependences))\n",
    "      continue;\n",
    "\n",
    "    if (SAI->isValueKind() || SAI->isArrayKind()) {\n",
    "      auto TheWrite = *(AllWrites.begin());\n",
    "      ScopArrayInfo *ExpandedArray = expandAccess(S, TheWrite);\n",
    "\n",
    "      mapAccess(S, AllReads, Dependences, ExpandedArray, true);\n",
    "    } else if (SAI->isPHIKind()) {\n",
    "      expandPhi(S, SAI, Dependences);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, we get the RAW dependences. Then we iterate over all ScopArrayInfo of the current Scop. If expandable, if it is a PHI, we use $expandPHI$ otherwise we expand directly with $expandAccess$ and $mapAccess$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details, diff and discussions can be found here : https://reviews.llvm.org/D36647. This patch has been merged into the actual version of Polly.\n",
    "\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "## Remaining work\n",
    "\n",
    "### MAXIMAL expansion\n",
    "### Select which SAI to expand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^f1]: Denis Barthou, Albert Cohen, and Jean-FranÃ§ois Collard. 2000. Maximal Static Expansion. Int. J. Parallel Program. 28, 3 (June 2000), 213-243. DOI=http://dx.doi.org/10.1023/A:1007500431910 \n",
    "\n",
    "[^f2]: P. Feautrier. 1988. Array expansion. In Proceedings of the 2nd international conference on Supercomputing (ICS '88), J. Lenfant (Ed.). ACM, New York, NY, USA, 429-441. DOI=http://dx.doi.org/10.1145/55364.55406 \n",
    "\n",
    "[^f3]: Dynamic Single Assignment. (n.d.). [ebook] Peter Vanbroekhoven. Available at: http://www.elis.ugent.be/aces/edegem2002/vanbroekhoven.pdf [Accessed 22 Aug. 2017]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

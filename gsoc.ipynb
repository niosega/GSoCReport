{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximal Static Expansion for efficient parallelization on GPU\n",
    "\n",
    "## Context\n",
    "\n",
    "### Polly\n",
    "My GSoC project is part of Polly. Polly is a loop and data-locality optimizer for LLVM. The optimisations are made using a mathematical model called polyhedral model. It models the memory access of the program. After modeling, transformations (tilling, loop fusion, loop unrolling ...) can be applied on the model to improve data-locality and/or parallelization. The aim of my project was to implement a transformation called Maximal Static Expansion (MSE).\n",
    "\n",
    "**TODO : Explain here dependences, memory access map, domain, range etc ...**\n",
    "\n",
    "### Maximal static expansion\n",
    "Data-dependences in a program can lead to a very bad automatic parallelization. Modern compilers use techniques to reduce the number of such dependences. One of them is Maximal Static Expansion. The MSE is a transformation which expand the memory access to and from Array or Scalar. The goal is to disambiguate memory accesses by assigning different memory locations to non-conflicting writes. This method is described in a paper written by Denis Barthou, Albert Cohen and Jean-Francois Collard.[^f1] \n",
    "Let take a example (from the article) to understand the principle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-cdf2a05d1563>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-cdf2a05d1563>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    int tmp;\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "int tmp;\n",
    "for (int i = 0; i < N; i++) {\n",
    "    tmp = i;\n",
    "    for (int j = 0; j < N; j++) {\n",
    "        tmp = tmp + i + j;\n",
    "    }\n",
    "    A[i] = tmp;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data-dependences induced by tmp make the two loops unparallelizable : the iteration j of the inner-loop needs value from the previous iteration and it is impossible to parrallelize the i-loop because tmp is used in all iterations.\n",
    "\n",
    "If we expand the accesses to tmp according to the outermost loop, we can then parallelize the i-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int tmp_exp[N];\n",
    "for (int i = 0; i < N; i++) {\n",
    "    tmp_exp[i] = i;\n",
    "    for (int j = 0; j < N; j++) {\n",
    "        tmp_exp[i] = tmp_exp[i] + i + j;\n",
    "    }\n",
    "    A[i] = tmp_exp[i];\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accesses to tmp are now made to/from a different location for each iteration of the i-loop. It is then possible to execute the different iteration on different computation units (GPU, CPU ...).\n",
    "\n",
    "### Static single assignement\n",
    "Due to lack of time, I was not able to implement **maximal** static expansion but only fully-indexed expansion. The principle of fully-index expansion is that each write goes to a different memory location. \n",
    "Let see the idea on an example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int tmp;\n",
    "for (int i = 0; i < N; i++) {\n",
    "    tmp = i;\n",
    "    for (int j = 0; j < N; j++) {\n",
    "        B[j] = tmp + 3;\n",
    "    }\n",
    "    A[i] = B[i];\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity, only the arrays will be expanded in this example. The fully expanded version is :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int tmp;\n",
    "for (int i = 0; i < N; i++) {\n",
    "    tmp = i;\n",
    "    for (int j = 0; j < N; j++) {\n",
    "        B_exp[i][j] = tmp + 3;\n",
    "    }\n",
    "    A_exp[i] = B_exp[i][i];\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The details of fully-indexed expansion will be discussed in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## My work\n",
    "My project is part of Polly. I am a french student but during the GSoC I was a student at the university of Passau, Germany. The LooPo team welcome me and more especially Andreas Simbürger, one of my GSoC mentor and my master thesis supervisor. My other GSoC mentor is Michael Kruse, one of the main contributor to Polly, actually working in France.\n",
    "I'd like to thank all the people that help and guide me and more especially Andreas and Michael. \n",
    "\n",
    "### JSON bug fix\n",
    "As first step in open source software development and to get familiar with Polly/LLVM development process, I fixed a open bug in Polly. Polly can import data from a JSON file (in case of Polly called jscop file). It can import new array, new memory access, new schedule or new context. In the previous implementation of JSONImporter, Polly did not check if the data in the jscop file were plausible and consistent before import. This can lead to failure in the remaining part of the Polly pipeline. My work was to implement plausibility and consistency checks. Details, diff and discussions can be found here : https://reviews.llvm.org/D32739. This patch has been merged into the actual version of Polly.\n",
    "\n",
    "### Allocate array on heap\n",
    "During transformation, Polly can create new arrays because it helps optimizing the program. Before GSoC, it was only possible to allocate array on the stack. It is sufficient for small arrays, but while doing expansion, we possibly handle very large arrays. For example, if we want to expand fully this simple code :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (int i = 0; i < N; i++)\n",
    "  for (int j = 0; j < N; j++)\n",
    "    for (int k = 0; k < N; k++)\n",
    "      for (int l = 0; l < N; l++)\n",
    "        A[l] = 3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expansion would lead to the following code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (int i = 0; i < N; i++)\n",
    "  for (int j = 0; j < N; j++)\n",
    "    for (int k = 0; k < N; k++)\n",
    "      for (int l = 0; l < N; l++)\n",
    "        A_exp[i][j][k][l] = 3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the value of N, A_exp can have a huge number of elements. If N = 100, we have $100*100*100*100 = 100000000 = 10^8$ elements ! Thus, the possibility to allocate array on heap was needed. \n",
    "\n",
    "The array allocation is implemented in the IslNodeBuilder. Here is the part of the code that do the allocation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "void IslNodeBuilder::allocateNewArrays(BBPair StartExitBlocks) {\n",
    "  for (auto &SAI : S.arrays()) {\n",
    "    if (SAI->getBasePtr())\n",
    "      continue;\n",
    "\n",
    "    assert(SAI->getNumberOfDimensions() > 0 && SAI->getDimensionSize(0) &&\n",
    "           \"The size of the outermost dimension is used to declare newly \"\n",
    "           \"created arrays that require memory allocation.\");\n",
    "\n",
    "    Type *NewArrayType = nullptr;\n",
    "\n",
    "    // Get the size of the array = size(dim_1)*...*size(dim_n)\n",
    "    uint64_t ArraySizeInt = 1;\n",
    "    for (int i = SAI->getNumberOfDimensions() - 1; i >= 0; i--) {\n",
    "      auto *DimSize = SAI->getDimensionSize(i);\n",
    "      unsigned UnsignedDimSize = static_cast<const SCEVConstant *>(DimSize)\n",
    "                                     ->getAPInt()\n",
    "                                     .getLimitedValue();\n",
    "\n",
    "      if (!NewArrayType)\n",
    "        NewArrayType = SAI->getElementType();\n",
    "\n",
    "      NewArrayType = ArrayType::get(NewArrayType, UnsignedDimSize);\n",
    "      ArraySizeInt *= UnsignedDimSize;\n",
    "    }\n",
    "\n",
    "    if (SAI->isOnHeap()) {\n",
    "      LLVMContext &Ctx = NewArrayType->getContext();\n",
    "\n",
    "      // Get the IntPtrTy from the Datalayout\n",
    "      auto IntPtrTy = DL.getIntPtrType(Ctx);\n",
    "\n",
    "      // Get the size of the element type in bits\n",
    "      unsigned Size = SAI->getElemSizeInBytes();\n",
    "\n",
    "      // Insert the malloc call at polly.start\n",
    "      auto InstIt = std::get<0>(StartExitBlocks)->getTerminator();\n",
    "      auto *CreatedArray = CallInst::CreateMalloc(\n",
    "          &*InstIt, IntPtrTy, SAI->getElementType(),\n",
    "          ConstantInt::get(Type::getInt64Ty(Ctx), Size),\n",
    "          ConstantInt::get(Type::getInt64Ty(Ctx), ArraySizeInt), nullptr,\n",
    "          SAI->getName());\n",
    "\n",
    "      SAI->setBasePtr(CreatedArray);\n",
    "\n",
    "      // Insert the free call at polly.exiting\n",
    "      CallInst::CreateFree(CreatedArray,\n",
    "                           std::get<1>(StartExitBlocks)->getTerminator());\n",
    "\n",
    "    } else {\n",
    "      auto InstIt = Builder.GetInsertBlock()\n",
    "                        ->getParent()\n",
    "                        ->getEntryBlock()\n",
    "                        .getTerminator();\n",
    "\n",
    "      auto *CreatedArray = new AllocaInst(NewArrayType, DL.getAllocaAddrSpace(),\n",
    "                                          SAI->getName(), &*InstIt);\n",
    "      CreatedArray->setAlignment(PollyTargetFirstLevelCacheLineSize);\n",
    "      SAI->setBasePtr(CreatedArray);\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My work in this method is the size computation and the heap allocation part. The remaining code was already in place.\n",
    "\n",
    "Let explain step by step the principle of the heap allocation.\n",
    "\n",
    "First of all, to allocate array, we need to have the size of the memory chunk we want to allocate. To do that, we simply iterate over the dimension of the ScopArrayInfo and multiply the size of each dimensions. This is done by this code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    // Get the size of the array = size(dim_1)*...*size(dim_n)\n",
    "    uint64_t ArraySizeInt = 1;\n",
    "    for (int i = SAI->getNumberOfDimensions() - 1; i >= 0; i--) {\n",
    "      auto *DimSize = SAI->getDimensionSize(i);\n",
    "      unsigned UnsignedDimSize = static_cast<const SCEVConstant *>(DimSize)\n",
    "                                     ->getAPInt()\n",
    "                                     .getLimitedValue();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually do the expansion, we need to add a malloc call at the beginning of the polly section, called polly.start. After each malloc, a free must be present. The free call is added at polly.end. These two BasicBlock (polly.start and polly.end) are passed to allocateNewArray as a BBPair. We choose polly.start and polly.end as insertion points after a dense discussion with the polly community because this certify that there is no use-after-free (for instance in case of Scop in a loop) and that all memory cells allocated with a malloc are free'd when we don't need them anymore.\n",
    "\n",
    "To get polly.start and polly.end, we modify executeScopConditionnaly such that it return both start block and end block of the scop. In the previous version of Polly, executeScopConditionnaly only return polly.start. People who wanted polly.end assume that there is no BasicBlock between polly.start and polly.end, so they just take the successor of polly.start. \n",
    "\n",
    "The malloc call insertion is made by this code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    auto *CreatedArray = CallInst::CreateMalloc(\n",
    "              &*InstIt, IntPtrTy, SAI->getElementType(),\n",
    "              ConstantInt::get(Type::getInt64Ty(Ctx), Size),\n",
    "              ConstantInt::get(Type::getInt64Ty(Ctx), ArraySizeInt), nullptr,\n",
    "              SAI->getName());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The free call insertion is made by this code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    CallInst::CreateFree(CreatedArray, std::get<1>(StartExitBlocks)->getTerminator());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details, diff and discussions can be found here : https://reviews.llvm.org/D33688. This patch has been merged into the actual version of Polly.\n",
    "\n",
    "### Array Fully indexed exp\n",
    "#### Principle\n",
    "As a first step in term of expansion, we choose to expand only arrays because we thought that it was an easy step to build expansion infrastructure. We also choose to no implement the **maximal** expansion in this step, to focus our efforts on the architecture of expansion : we implement a Fully-index expansion. The principle is that, for each array in the Scop, we expand the write to the array according to the loop nest and then we map the reads to the right iteration of the newly create ScopArrayInfo. Let see this on an example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int tmp;\n",
    "for (int i = 0; i < N; i++) {\n",
    "    tmp = i;\n",
    "    for (int j = 0; j < N; j++) {\n",
    "S:      B[j] = tmp + 3;\n",
    "    }\n",
    "T:  A[i] = B[i];\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The write to B occurs inside the i and j loops. Therefore, the expanded version of B must be a two-dimensional array indexed by i and j. The write to A occurs inside the i loop only, therefore it would no need expansion. But for the sake of simplicity, we still create an expanded version of A. After write expansion, the code would look like that :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int tmp;\n",
    "for (int i = 0; i < N; i++) {\n",
    "    tmp = i;\n",
    "    for (int j = 0; j < N; j++) {\n",
    "S:      B_exp[i][j] = tmp + 3;\n",
    "    }\n",
    "T:  A_exp[i] = B[i];\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no read from A, so the expansion of A is done. There is a read from B in the statement T. At this step, we need the RAW dependences. In our case, statement T depends on statement S because the memory location reads by statement T is written by statetement S during j-loop iterations. The dependency looks like :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\{ T[i] \\rightarrow S[i][i] : 0\\le i \\le N \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know that the statement T must read its value from the statement S at index [i,i], we only have to know the name of the expanded version of B and modify the read. After read expansion, the source code looks like that :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int tmp;\n",
    "for (int i = 0; i < N; i++) {\n",
    "    tmp = i;\n",
    "    for (int j = 0; j < N; j++) {\n",
    "S:      B_exp[i][j] = tmp + 3;\n",
    "    }\n",
    "T:  A_exp[i] = B_exp[i][i];\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More details can be found in these two articles[^f2][^f3].\n",
    "\n",
    "#### Implementation\n",
    "Let see now how this principle has been implemented in Polly.\n",
    "\n",
    "Static expansion has been implemented as a ScopPass, which is a Pass triggered on every Scop detected by Polly. Guarded by an option, it is possible to ask Polly to do the expansion by adding **-polly-enable-mse** to clang or **-polly-mse** to opt command line. \n",
    "\n",
    "Here is the 'main' of static expansion. This code is straightforward and explains by itself the idea of expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  // Get the RAW Dependences.\n",
    "  auto &DI = getAnalysis<DependenceInfo>();\n",
    "  auto &D = DI.getDependences(Dependences::AL_Reference);\n",
    "  auto Dependences = isl::give(D.getDependences(Dependences::TYPE_RAW));\n",
    "\n",
    "  for (auto SAI : S.arrays()) {\n",
    "    SmallPtrSet<MemoryAccess *, 4> AllWrites;\n",
    "    SmallPtrSet<MemoryAccess *, 4> AllReads;\n",
    "    if (!isExpandable(SAI, AllWrites, AllReads, S, Dependences))\n",
    "      continue;\n",
    "\n",
    "    auto TheWrite = *(AllWrites.begin());\n",
    "    ScopArrayInfo *ExpandedArray = expandWrite(S, TheWrite);\n",
    "\n",
    "    for (MemoryAccess *MA : AllReads)\n",
    "      expandRead(S, MA, Dependences, ExpandedArray);\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three first line is just the way to get dependences from Polly infrastructure. We request the DependenceInfo analysis for RAW dependences, using the Reference level statement. In a first iteration, we were using Statement Level statement. But this causes bugs. Full discussion and bug fixing can be found here :  https://reviews.llvm.org/D36791.\n",
    "\n",
    "Then, we iterate over ScopArrayInfo in the Scop we are processing. We check if the ScopArrayInfo is expandable. If yes, we expand the write following the principle describe below and after we expand the reads.\n",
    "\n",
    "TODO : expandability check\n",
    "TODO : expand write\n",
    "TODO : expand reads\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details, diff and discussions can be found here : https://reviews.llvm.org/D34982. This patch and the bug fixing one have been merged into the actual version of Polly.\n",
    "\n",
    "clear deps : https://reviews.llvm.org/D36926\n",
    "clears deps michael : https://reviews.llvm.org/D37010\n",
    "\n",
    "### Scalar Fully indexed exp\n",
    "Details, diff and discussions can be found here : https://reviews.llvm.org/D36647. This patch has been merged into the actual version of Polly.\n",
    "\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "## Remaining work\n",
    "\n",
    "### MAXIMAL expansion\n",
    "### Select which SAI to expand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^f1]: Denis Barthou, Albert Cohen, and Jean-François Collard. 2000. Maximal Static Expansion. Int. J. Parallel Program. 28, 3 (June 2000), 213-243. DOI=http://dx.doi.org/10.1023/A:1007500431910 \n",
    "[^f2]: P. Feautrier. 1988. Array expansion. In Proceedings of the 2nd international conference on Supercomputing (ICS '88), J. Lenfant (Ed.). ACM, New York, NY, USA, 429-441. DOI=http://dx.doi.org/10.1145/55364.55406 \n",
    "[^f3]: Dynamic Single Assignment. (n.d.). [ebook] Peter Vanbroekhoven. Available at: http://www.elis.ugent.be/aces/edegem2002/vanbroekhoven.pdf [Accessed 22 Aug. 2017]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
